{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3343762-ca45-42e9-9f3e-685f283ce026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def noncon_vector_function(input_data, centers, amplitudes, sigmas, transform_matrix=None, center_batch_size=200):\n",
    "    \"\"\"\n",
    "    Compute the vector field at the given input points using Gaussian contributions, with optional linear transformation.\n",
    "    \n",
    "    Args:\n",
    "        input_data (torch.Tensor): Tensor of shape (num_samples, dimension) containing the input points.\n",
    "        centers (torch.Tensor): Tensor of shape (num_centers, dimension) containing the Gaussian centers.\n",
    "        amplitudes (torch.Tensor): Tensor of shape (num_centers,) containing the Gaussian amplitudes.\n",
    "        sigmas (torch.Tensor): Tensor of shape (num_centers,) containing the Gaussian sigmas.\n",
    "        transform_matrix (torch.Tensor): Tensor of shape (dimension, dimension) describing how to mix the output components. \n",
    "                                        If None, no transformation is applied.\n",
    "        center_batch_size (int): Maximum number of centers to process at a time. Default is 200.\n",
    "    \n",
    "    Returns:\n",
    "        force (torch.Tensor): Tensor of shape (num_samples, dimension) containing the transformed vector field values.\n",
    "    \"\"\"\n",
    "    num_samples = input_data.shape[0]\n",
    "    dimension = input_data.shape[1]\n",
    "    num_centers = centers.shape[0]\n",
    "\n",
    "    # Initialize the output tensor to store the force values\n",
    "    force = torch.zeros((num_samples, dimension), device=input_data.device)\n",
    "\n",
    "    # Process centers, amplitudes, and sigmas in batches\n",
    "    for i in range(0, num_centers, center_batch_size):\n",
    "        # Get the current batch of centers, amplitudes, and sigmas\n",
    "        batch_end = min(i + center_batch_size, num_centers)\n",
    "        batch_centers = centers[i:batch_end]  # Shape: (batch_size, dimension)\n",
    "        batch_amplitudes = amplitudes[i:batch_end]  # Shape: (batch_size,)\n",
    "        batch_sigmas = sigmas[i:batch_end]  # Shape: (batch_size,)\n",
    "\n",
    "        # Expand input_data and batch_centers for broadcasting\n",
    "        input_data_expanded = input_data.unsqueeze(1)  # Shape: (num_samples, 1, dimension)\n",
    "        centers_expanded = batch_centers.unsqueeze(0)  # Shape: (1, batch_size, dimension)\n",
    "\n",
    "        # Compute differences between input points and batch centers\n",
    "        diff = input_data_expanded - centers_expanded  # Shape: (num_samples, batch_size, dimension)\n",
    "\n",
    "        # Compute the squared distances and Gaussian exponent terms\n",
    "        squared_distances = torch.sum(diff**2, dim=2)  # Shape: (num_samples, batch_size)\n",
    "        exp_terms = torch.exp(-squared_distances / (2 * batch_sigmas**2))  # Shape: (num_samples, batch_size)\n",
    "\n",
    "        # Compute the gradients for each dimension\n",
    "        grad = (batch_amplitudes / batch_sigmas**2).unsqueeze(0).unsqueeze(-1) * diff * exp_terms.unsqueeze(-1)  # Shape: (num_samples, batch_size, dimension)\n",
    "\n",
    "        # Sum contributions from the current batch of centers\n",
    "        batch_force = -torch.sum(grad, dim=1)  # Shape: (num_samples, dimension)\n",
    "\n",
    "        # Accumulate the batch results in the output tensor\n",
    "        force += batch_force\n",
    "\n",
    "    # Apply transformation if specified\n",
    "    if transform_matrix is not None:\n",
    "        force = torch.einsum('ij,sj->si', transform_matrix, force)  # Shape: (num_samples, dimension)\n",
    "\n",
    "    return force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9610c56a-34b8-4c47-9a92-aea92899c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation matrix:\n",
      "tensor([[-1.3150,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -0.2016],\n",
      "        [ 0.0000, -0.9597,  0.0000]])\n",
      "\n",
      "Original force (sample 0): tensor([-2.9441,  1.9333, -0.0315])\n",
      "Transformed force (sample 0): tensor([ 3.8715,  0.0064, -1.8554])\n",
      "\n",
      "Jacobian of original force at sample 0:\n",
      "tensor([[ 2.5398, -2.5748, -0.8971],\n",
      "        [-2.5748, -3.4490,  0.5242],\n",
      "        [-0.8971,  0.5242, -3.2213]], grad_fn=<CopySlices>)\n",
      "\n",
      "Is the original Jacobian symmetric (conservative)? True\n",
      "\n",
      "Jacobian of transformed force at sample 0:\n",
      "tensor([[-3.3399,  3.3859,  1.1797],\n",
      "        [ 0.1809, -0.1057,  0.6495],\n",
      "        [ 2.4711,  3.3100, -0.5030]], grad_fn=<CopySlices>)\n",
      "\n",
      "Is the transformed Jacobian symmetric (conservative)? False\n"
     ]
    }
   ],
   "source": [
    "# Test parameters\n",
    "dimension = 3\n",
    "num_samples = 10\n",
    "num_centers = 100\n",
    "\n",
    "# Generate random input data, centers, amplitudes, and sigmas\n",
    "input_data = torch.randn((num_samples, dimension))\n",
    "centers = torch.randn((num_centers, dimension))\n",
    "amplitudes = torch.randn((num_centers,))\n",
    "sigmas = torch.abs(torch.randn((num_centers,))) + 0.1  # Ensure sigmas > 0\n",
    "\n",
    "# Generate a random transformation matrix (mostly zeros, with some swaps/scales)\n",
    "transform_matrix = torch.zeros((dimension, dimension))\n",
    "for i in range(dimension):\n",
    "    # Randomly choose another component to swap with or scale\n",
    "    j = torch.randint(0, dimension, (1,)).item()\n",
    "    transform_matrix[i, j] = torch.randn(1).item() * 2  - 1 # Random scaling\n",
    "\n",
    "print(\"Transformation matrix:\")\n",
    "print(transform_matrix)\n",
    "\n",
    "# Compute original and transformed forces\n",
    "original_force = noncon_vector_function(input_data, centers, amplitudes, sigmas)\n",
    "transformed_force = noncon_vector_function(input_data, centers, amplitudes, sigmas, transform_matrix)\n",
    "\n",
    "# Print some samples to verify transformation\n",
    "print(\"\\nOriginal force (sample 0):\", original_force[0])\n",
    "print(\"Transformed force (sample 0):\", transformed_force[0])\n",
    "\n",
    "# Check if the transformed field is non-conservative (Jacobian not symmetric)\n",
    "sample_point = input_data[0].unsqueeze(0)  # Pick a single point to test\n",
    "sample_point.requires_grad = True\n",
    "\n",
    "# Compute Jacobian of the transformed force\n",
    "force_at_point = noncon_vector_function(sample_point, centers, amplitudes, sigmas)\n",
    "jacobian = torch.zeros((dimension, dimension))\n",
    "for i in range(dimension):\n",
    "    grad_output = torch.zeros_like(force_at_point)\n",
    "    grad_output[0, i] = 1.0\n",
    "    gradients = torch.autograd.grad(force_at_point, sample_point, grad_outputs=grad_output, create_graph=True)[0]\n",
    "    jacobian[i] = gradients[0]\n",
    "\n",
    "print(\"\\nJacobian of original force at sample 0:\")\n",
    "print(jacobian)\n",
    "\n",
    "# Check symmetry (if not symmetric, field is non-conservative)\n",
    "is_symmetric = torch.allclose(jacobian, jacobian.t(), atol=1e-6)\n",
    "print(\"\\nIs the original Jacobian symmetric (conservative)?\", is_symmetric)\n",
    "\n",
    "# Compute Jacobian of the transformed force\n",
    "force_at_point = noncon_vector_function(sample_point, centers, amplitudes, sigmas, transform_matrix)\n",
    "jacobian = torch.zeros((dimension, dimension))\n",
    "for i in range(dimension):\n",
    "    grad_output = torch.zeros_like(force_at_point)\n",
    "    grad_output[0, i] = 1.0\n",
    "    gradients = torch.autograd.grad(force_at_point, sample_point, grad_outputs=grad_output, create_graph=True)[0]\n",
    "    jacobian[i] = gradients[0]\n",
    "\n",
    "print(\"\\nJacobian of transformed force at sample 0:\")\n",
    "print(jacobian)\n",
    "\n",
    "# Check symmetry (if not symmetric, field is non-conservative)\n",
    "is_symmetric = torch.allclose(jacobian, jacobian.t(), atol=1e-6)\n",
    "print(\"\\nIs the transformed Jacobian symmetric (conservative)?\", is_symmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e31bb-9f4b-43ce-a315-5820901d264d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
