{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b919b4-d64c-41f1-bb9c-6882d6a02c40",
   "metadata": {},
   "source": [
    "# Generating Low Dimensional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ba0e15-f29d-4558-b56b-76b25219b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed num_centers: [2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_1\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_2\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_3\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_4\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_5\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_6\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_7\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_8\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_9\\dataset_dim_20.txt'\n",
      "Dataset for dimension 2 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_2.txt'\n",
      "Dataset for dimension 3 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_3.txt'\n",
      "Dataset for dimension 5 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_5.txt'\n",
      "Dataset for dimension 8 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_8.txt'\n",
      "Dataset for dimension 10 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_10.txt'\n",
      "Dataset for dimension 12 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_12.txt'\n",
      "Dataset for dimension 15 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_15.txt'\n",
      "Dataset for dimension 18 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_18.txt'\n",
      "Dataset for dimension 20 with 2 centers saved to 'datasets\\dataset_10\\dataset_dim_20.txt'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "# Add parent directory to sys.path\n",
    "parent_dir = Path.cwd().parent.parent\n",
    "sys.path.append(str(parent_dir))\n",
    "# Import modules\n",
    "from dataset_gen import average_sphere_volume, generate_and_save_datasets, compute_volume_ratios\n",
    "\n",
    "dimensions = [2, 3, 5, 8, 10, 12, 15, 18, 20]  # List of dimensions to generate datasets for\n",
    "output_folder = 'datasets'\n",
    "amplitude = 1.0  # Fixed amplitude for all Gaussians (set to None for random amplitudes)\n",
    "sigma_range=(0.5, 1.0)\n",
    "num_sets = 10  # Number of datasets to generate for each dimension\n",
    "base_seed = 42  # Base seed for reproducibility\n",
    "\n",
    "num_centers = [int(2) for d in dimensions]\n",
    "print(\"Computed num_centers:\", num_centers)\n",
    "generate_and_save_datasets(dimensions, num_centers, output_folder, num_sets, base_seed, amplitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f3e4a-7e49-4897-8bb0-92469da0a1c9",
   "metadata": {},
   "source": [
    "# Training and Test Point Generation \n",
    "\n",
    "Can be modified to turn on non-conservative vector field generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb738a5-29ae-4365-a213-9c3950b8acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: dataset_1\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_10\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_2\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_3\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_4\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_5\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_6\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_7\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_8\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Processing folder: dataset_9\n",
      "Processing dataset_dim_10.txt with dimension 10\n",
      "Saved train/test data for dataset_dim_10.txt\n",
      "Processing dataset_dim_12.txt with dimension 12\n",
      "Saved train/test data for dataset_dim_12.txt\n",
      "Processing dataset_dim_15.txt with dimension 15\n",
      "Saved train/test data for dataset_dim_15.txt\n",
      "Processing dataset_dim_18.txt with dimension 18\n",
      "Saved train/test data for dataset_dim_18.txt\n",
      "Processing dataset_dim_2.txt with dimension 2\n",
      "Saved train/test data for dataset_dim_2.txt\n",
      "Processing dataset_dim_20.txt with dimension 20\n",
      "Saved train/test data for dataset_dim_20.txt\n",
      "Processing dataset_dim_3.txt with dimension 3\n",
      "Saved train/test data for dataset_dim_3.txt\n",
      "Processing dataset_dim_5.txt with dimension 5\n",
      "Saved train/test data for dataset_dim_5.txt\n",
      "Processing dataset_dim_8.txt with dimension 8\n",
      "Saved train/test data for dataset_dim_8.txt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "# Add parent directory to sys.path\n",
    "parent_dir = Path.cwd().parent\n",
    "sys.path.append(str(parent_dir))\n",
    "# Import modules\n",
    "from dataset_gen import vector_function, random_input_points, generate_random_transform_matrix\n",
    "\n",
    "# Folder containing datasets\n",
    "dataset_folder = \"datasets\"\n",
    "num_samples = 10000 #Number of test and train data points.\n",
    "\n",
    "def print_vector_stats(points, values, label):\n",
    "    \"\"\"Helper function to calculate and print vector statistics\"\"\"\n",
    "    avg_vector = np.mean(values.numpy(), axis=0)\n",
    "    vector_magnitude = np.linalg.norm(avg_vector)\n",
    "    print(f\"\\n{label} Vector Statistics:\")\n",
    "    print(f\"Average vector: {avg_vector}\")\n",
    "    print(f\"Vector magnitude: {vector_magnitude:.4f}\")\n",
    "    print(f\"Min value: {np.min(values.numpy()):.4f}\")\n",
    "    print(f\"Max value: {np.max(values.numpy()):.4f}\")\n",
    "    print(f\"Mean absolute value: {np.mean(np.abs(values.numpy())):.4f}\")\n",
    "    return avg_vector\n",
    "\n",
    "# Iterate through all subfolders in the dataset folder\n",
    "for subfolder in os.listdir(dataset_folder):\n",
    "    subfolder_path = os.path.join(dataset_folder, subfolder)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f\"Processing folder: {subfolder}\")\n",
    "\n",
    "        # Create train and test subfolders if they don't exist\n",
    "        train_folder = os.path.join(subfolder_path, \"train\")\n",
    "        test_folder = os.path.join(subfolder_path, \"test\")\n",
    "        os.makedirs(train_folder, exist_ok=True)\n",
    "        os.makedirs(test_folder, exist_ok=True)\n",
    "        \n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith(\".txt\"):\n",
    "                filepath = os.path.join(subfolder_path, filename)\n",
    "                loaded_data = np.loadtxt(filepath)\n",
    "        \n",
    "                dimension = loaded_data.shape[1] - 2\n",
    "                print(f\"Processing {filename} with dimension {dimension}\")\n",
    "                \n",
    "                # Separate the data\n",
    "                centers = torch.tensor(loaded_data[:, :dimension], dtype=torch.float32)\n",
    "                amplitudes = torch.tensor(loaded_data[:, -2], dtype=torch.float32)\n",
    "                sigmas = torch.tensor(loaded_data[:, -1], dtype=torch.float32)\n",
    "\n",
    "                # Generate random transformation matrix using dimension as seed\n",
    "                # Only necessary for testing a non-conservative vector field.\n",
    "                #transform_matrix = generate_random_transform_matrix(dimension, seed=dimension)\n",
    "                #print(\"Generated transformation matrix:\")\n",
    "                #print(transform_matrix)\n",
    "        \n",
    "                # Generate points and values\n",
    "                train_points = random_input_points(num_samples, dimension, seed=dimension)\n",
    "                test_points = random_input_points(num_samples, dimension, seed=dimension+30)\n",
    "                train_values = vector_function(train_points, centers, amplitudes, sigmas, center_batch_size=100)# transform_matrix, center_batch_size=100)\n",
    "                test_values = vector_function(test_points, centers, amplitudes, sigmas, center_batch_size=100)# transform_matrix, center_batch_size=100)\n",
    "\n",
    "                # Print statistics - Uncomment to see statistics\n",
    "                #train_avg = print_vector_stats(train_points, train_values, \"Training\")\n",
    "                #test_avg = print_vector_stats(test_points, test_values, \"Test\")\n",
    "                \n",
    "                # Save files\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                \n",
    "                # Save train data\n",
    "                train_data = np.column_stack((train_points.numpy(), train_values.numpy()))\n",
    "                train_filename = os.path.join(train_folder, f\"{base_name}_train.txt\")\n",
    "                np.savetxt(train_filename, train_data)\n",
    "                \n",
    "                # Save test data\n",
    "                test_data = np.column_stack((test_points.numpy(), test_values.numpy()))\n",
    "                test_filename = os.path.join(test_folder, f\"{base_name}_test.txt\")\n",
    "                np.savetxt(test_filename, test_data)\n",
    "                \n",
    "                print(f\"Saved train/test data for {filename}\")\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e660f0-9bfc-44b1-8975-8f424afa8f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diffusion-env)",
   "language": "python",
   "name": "diffusion-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
